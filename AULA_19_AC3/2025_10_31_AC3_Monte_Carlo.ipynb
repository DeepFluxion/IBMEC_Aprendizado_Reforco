{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb16b05",
   "metadata": {},
   "source": [
    "# Atividade Complementar 3 \n",
    "\n",
    "### üìãAtividade Complementar 3 ‚Äì Temporal Diference- INSTRU√á√ïES GERAIS:\n",
    "1.\tVoc√™ pode executar esta atividade no Google Colab ou executar no seu computador. Execute as c√©lulas com implementa√ß√£o antes de executar as tarefas.\n",
    "2.\tVedado acesso a celulares e consulta a sites externos como ChatGPT, Claude.ai, Gemini\n",
    "3.\tPermitida a consulta ao material de aula e notebooks do Github\n",
    "### üìä Formato de Entrega\n",
    "- Use o template word (.docx) para download no SAVA e entregue um pdf no SAVA\n",
    "- Notebook com os scripts desenvolvido\n",
    "- Data de Entrega : 31/10/2025 at√© 00:00\n",
    "### Para cada quest√£o:\n",
    "1.\tPrint/screenshot do resultado principal (gr√°fico ou tabela de win rates)\n",
    "2.\tRespostas para cada pergunta procure esclarecer os conceitos empregados e apresentados em aula, como defini√ß√µes e pseudo c√≥digos\n",
    "3.\tObserva√ß√£o adicional (opcional): algo interessante que voc√™ notou\n",
    "\n",
    "FONTES DE CONSULTA\n",
    "---\n",
    "### √â PERMITIDA A CONSULTA AS SEGUINTES FONTES QUALQUER OUTRA CONSULTA DURANTE A REVIS√ÉO DA AC3 √â PROIBIDA.\n",
    "[RESUMO TE√ìRICO](https://github.com/DeepFluxion/IBMEC_Aprendizado_Reforco/blob/main/GridWorld_Project/Resumo_Teorico_TD_MC.md)   \n",
    "[Aula_18_Tutorial_Completo_MC_TD_GW](https://github.com/DeepFluxion/IBMEC_Aprendizado_Reforco/blob/main/GridWorld_Project/Aula_18_Tutorial_Completo_MC_TD_GW.ipynb)   \n",
    "[Aula_18_Implementacao_Ambiente_GridWorl](https://github.com/DeepFluxion/IBMEC_Aprendizado_Reforco/blob/main/GridWorld_Project/Aula_18_Implementacao_Ambiente_GridWorld.ipynb)\n",
    "Aula_18_Tutorial_Completo_MC_TD_GW.ipynb)   \n",
    "[GUIA COLAB](https://github.com/DeepFluxion/IBMEC_Aprendizado_Reforco/blob/main/GridWorld_Project/GUIA_COLAB.md)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8aee4",
   "metadata": {},
   "source": [
    "# EXECUTE A C√âLULA ABAIXO CASO ESTEJA NO COLAB\n",
    "---\n",
    "CASO CONT√ÅRIO PULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f54b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso esteja executando local baixe os arquivos do Github e passe para os imports\n"
     ]
    }
   ],
   "source": [
    "# C√©lula 1: Upload dos arquivos Python\n",
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    print(\"üì§ Fa√ßa upload dos 3 arquivos Python:\")\n",
    "    print(\"   1. environment.py\")\n",
    "    print(\"   2. algorithms.py\")\n",
    "    print(\"   3. visualization.py\")\n",
    "    print()\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    print(\"\\n‚úÖ Arquivos carregados com sucesso!\")\n",
    "    print(f\"   Total: {len(uploaded)} arquivo(s)\")\n",
    "except:\n",
    "    print('Caso esteja executando local baixe os arquivos do Github e passe para os imports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31ea899a-b991-4892-b64e-28928bf06e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì M√≥dulos importados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Imports b√°sicos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configura√ß√£o para notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Importar m√≥dulos de RL\n",
    "from environment import (\n",
    "    GridWorld,\n",
    "    create_classic_gridworld,\n",
    "    create_custom_gridworld,\n",
    "    create_cliff_world,\n",
    "    create_cliff_world_2,\n",
    "    print_gridworld_info\n",
    ")\n",
    "\n",
    "from algorithms import (\n",
    "    # Predi√ß√£o\n",
    "    td_zero_prediction,\n",
    "    first_visit_mc_prediction,\n",
    "    # Controle\n",
    "    sarsa,\n",
    "    q_learning,\n",
    "    expected_sarsa,\n",
    "    first_visit_mc_control,\n",
    "    mc_exploring_starts,\n",
    "    # Auxiliares\n",
    "    get_greedy_policy\n",
    ")\n",
    "\n",
    "from visualization import (\n",
    "    visualize_gridworld,\n",
    "    visualize_q_values,\n",
    "    visualize_q_table_detailed,\n",
    "    plot_learning_curves,\n",
    "    plot_value_evolution,\n",
    "    plot_value_heatmap,\n",
    "    plot_q_value_heatmap,\n",
    "    compare_algorithms,\n",
    "    print_q_table\n",
    ")\n",
    "\n",
    "print(\"‚úì M√≥dulos importados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03055839",
   "metadata": {},
   "source": [
    "# Q.1. VALOR 1 PONTO\n",
    "\n",
    "### Crie um GridWorld Customizado com as seguintes caracter√≠sticas\n",
    "\n",
    "### Lay Out (Veja tamb√©m Template)\n",
    "\n",
    " Layout:\n",
    " -------\n",
    " ```\n",
    " [ ] [ ] [ ] [ ] [ ] [ ] [ ] [T1]\n",
    " [ ] [ ] [ ] [‚ñ†] [‚ñ†] [‚ñ†] [ ] [  ]\n",
    " [‚ñ†] [ ] [‚ñ†] [‚ñ†] [‚ñ†] [ ] [ ] [‚ñ† ]\n",
    " [ ] [ ] [ ] [‚ñ†] [ ] [ ] [ ] [  ]\n",
    " [ ] [ ] [ ] [ ] [ ] [ ] [ ] [  ]\n",
    " [S] [C] [C] [C] [C] [C] [C] [T2]\n",
    "```\n",
    "\n",
    "Legenda:\n",
    "* S  : Estado inicial t√≠pico (5,0)\n",
    "* ‚ñ†  : Parede em (1, 3), (1, 4), (1, 5),(2, 0), (2, 2), (2, 3), (2, 4),(2, 7),(3, 3), #(3, 4), (3, 5\n",
    "* T1 : Terminal positivo em (0,3) Recompensa = 750.0\n",
    "* T2 : Terminal positivo em (5,7) Recompensa = 1000.0 \n",
    "* C : Terminal negativo em (5, 1) recompensa = -100.0,  #Precipio\n",
    "* C : Terminal negativo em (5, 2) recompensa = -100.0,  #Precipio\n",
    "* C : Terminal negativo em (5, 3) recompensa = -100.0,  #Precipio\n",
    "* C : Terminal negativo em (5, 4) recompensa = -100.0,  #Precipio\n",
    "* C : Terminal negativo em (5, 5) recompensa = -100.0,  #Precipio\n",
    "* C : Terminal negativo em (5, 6) recompensa = -100.0,  #Precipio\n",
    "\n",
    "Configura√ß√£o\n",
    "* Tamanho: 6 linhas x 8 colunas\n",
    "* Fator de desconto: Œ≥ = 0.95\n",
    "* Ru√≠do: 30% (0.3)\n",
    "* Living reward: -10.00\n",
    "\n",
    "Cole a imagem do ambiente e seus atributos gerados abaixo - (Dica: coloque o curso sobre a figura e clique com o bota√µ direito do mouse e copie a imagem e cole no arquivo world)\n",
    "\n",
    "> **DICA** Use a fun√ß√£o `create_custom_gridworld()` e `visualize_gridworld()` e `print_gridworld_info()`para gerar as imagens e testos necess√°rios e cole no template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69868cc-34ca-431f-ad5d-8b403d59df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar grid personalizado conforme as expecifica√ß√µes\n",
    "# gw_custom = create_custom_gridworld(\n",
    "#\n",
    "# # Seu C√≥digo aqui\n",
    "#\n",
    "# )\n",
    "# \n",
    "# # Visualizar ambiente\n",
    "# visualize_gridworld(gw_custom, title=\"Grid # Personalizado *x6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5042c94c-4738-48f0-83bb-67afa961101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_gridworld_info(gw_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d92fa",
   "metadata": {},
   "source": [
    "# Q.2 VALOR 1 PONTO\n",
    "\n",
    "### Treine o este ambiente com os seguintes par√¢metros: \n",
    "* Algoritmo: SARSA\n",
    "* Epis√≥dios: 5000\n",
    "* Alpha: 0.05\n",
    "* Gamma: 0.9\n",
    "* Episilon: 0.1\n",
    "Use as seguintes fun√ß√µes para exibir os resultados:\n",
    "### Treinamento:\n",
    "```python\n",
    "Q_sarsa, rewards_sarsa = sarsa(gw_custom, **PARAMS, verbose=True)\n",
    "```\n",
    "### Pol√≠tica:\n",
    "```python\n",
    "visualize_gridworld(gw_custom, policy=policy, title=f\"{name} - Pol√≠tica\")\n",
    "```\n",
    "### Valores Q: \n",
    "```python\n",
    "visualize_q_values(Q, gw_custom, title=f\"{name} - Valores Q\")\n",
    "```\n",
    "### Q-values detalhados:  \n",
    "```python\n",
    "visualize_q_table_detailed(Q, gw_custom, title=f\"{name} - Q-Values Detalhados\")\n",
    "```\n",
    "Cole a imagem de cada um dos resultados obtidos abaixo, tome cuidado com o t√≠tulo do gr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "090c6dfe-a185-4258-ac56-53cd9d116fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√¢metros\n",
    "PARAMS = {\n",
    "    'n_episodes': 5000,\n",
    "    'alpha': 0.05,\n",
    "    'gamma': 0.9,\n",
    "    'epsilon': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc4a04f-6454-41a0-b976-e9381ad86aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Treinando SARSA...\n"
     ]
    }
   ],
   "source": [
    "# Treinar o algoritmo SARSA \n",
    "print(\"‚Üí Treinando SARSA...\")\n",
    "### SEU C√ìDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022591fa",
   "metadata": {},
   "source": [
    "# Q.3 VALOR 1 PONTO\n",
    "\n",
    "### Treine o este ambiente com os seguintes par√¢metros: \n",
    "* Algoritmo: Q - Learning\n",
    "* Epis√≥dios: 5000\n",
    "* Alpha: 0.05\n",
    "* Gamma: 0.9\n",
    "* Episilon: 0.1\n",
    "Use as seguintes fun√ß√µes para exibir os resultados:\n",
    "### Treinamento:\n",
    "```python\n",
    "Q_q_learning, rewards_q_learning = q_learning(gw_custom, **PARAMS, verbose=True)\n",
    "```\n",
    "### Pol√≠tica:\n",
    "```python\n",
    "visualize_gridworld(gw_custom, policy=policy, title=f\"{name} - Pol√≠tica\")\n",
    "```\n",
    "### Valores Q: \n",
    "```python\n",
    "visualize_q_values(Q, gw_custom, title=f\"{name} - Valores Q\")\n",
    "```\n",
    "### Q-values detalhados:  \n",
    "```python\n",
    "visualize_q_table_detailed(Q, gw_custom, title=f\"{name} - Q-Values Detalhados\")\n",
    "```\n",
    "Cole a imagem de cada um dos resultados obtidos abaixo, tome cuidado com o t√≠tulo do gr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b9405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Treinando Q-Learning...\n"
     ]
    }
   ],
   "source": [
    "# Treinar o algoritmo Q-Learning \n",
    "print(\"‚Üí Treinando Q-Learning...\")\n",
    "### SEU C√ìDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a028e6f",
   "metadata": {},
   "source": [
    "# Q.4 VALOR 1 PONTO\n",
    "\n",
    "### Treine o este ambiente com os seguintes par√¢metros: \n",
    "* Algoritmo: Expected SARSA\n",
    "* Epis√≥dios: 5000\n",
    "* Alpha: 0.05\n",
    "* Gamma: 0.9\n",
    "* Episilon: 0.1\n",
    "Use as seguintes fun√ß√µes para exibir os resultados:\n",
    "### Treinamento:\n",
    "```python\n",
    "Q_expected, rewards_expected = expected_sarsa(gw_custom, **PARAMS, verbose=True)\n",
    "```\n",
    "### Pol√≠tica:\n",
    "```python\n",
    "visualize_gridworld(gw_custom, policy=policy, title=f\"{name} - Pol√≠tica\")\n",
    "```\n",
    "### Valores Q: \n",
    "```python\n",
    "visualize_q_values(Q, gw_custom, title=f\"{name} - Valores Q\")\n",
    "```\n",
    "### Q-values detalhados:  \n",
    "```python\n",
    "visualize_q_table_detailed(Q, gw_custom, title=f\"{name} - Q-Values Detalhados\")\n",
    "```\n",
    "Cole a imagem de cada um dos resultados obtidos abaixo, tome cuidado com o t√≠tulo do gr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8d87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Treinando Expected SARSA...\n"
     ]
    }
   ],
   "source": [
    "# Treinar o algoritmo Expected SARSA \n",
    "print(\"‚Üí Treinando Expected SARSA...\")\n",
    "### SEU C√ìDIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef2e0e",
   "metadata": {},
   "source": [
    "# Q.5 VALOR TOTAL 3 PONTOS\n",
    "\n",
    "### Compare os algoritmos treinados SARSA, Q-Learning e Expected SARSA\n",
    "\n",
    "### Q.5 ITEM A VALOR DO ITEM 0.5 PONTOS\n",
    "Use as seguintes fun√ß√µes para exibir os resultados (retire os coment√°rios antes):\n",
    "\n",
    "```python\n",
    "# Visualizar curvas de aprendizado\n",
    "plot_learning_curves({\n",
    "    'SARSA': rewards_sarsa,\n",
    "    'Q-Learning': rewards_qlearning,\n",
    "    'Expected SARSA': rewards_expected\n",
    "}, window=500, title=\"Compara√ß√£o de Algoritmos TD\")\n",
    "\n",
    "# Comparar valores\n",
    "compare_algorithms({\n",
    "    'SARSA': Q_sarsa,\n",
    "    'Q-Learning': Q_qlearning,\n",
    "    'Expected SARSA': Q_expected\n",
    "}, gw_custom)\n",
    "\n",
    "# Visualizar pol√≠ticas aprendidas\n",
    "for name, Q in [('SARSA', Q_sarsa),\n",
    "                ('Q-Learning', Q_qlearning),\n",
    "                ('Expected SARSA', Q_expected)]:\n",
    "\n",
    "    policy = get_greedy_policy(Q, gw_custom)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name}\")\n",
    "    print('='*60)\n",
    "\n",
    "    # Pol√≠tica\n",
    "    visualize_gridworld(gw_custom, policy=policy, title=f\"{name} - Pol√≠tica\")\n",
    "\n",
    "    # Valores Q\n",
    "    visualize_q_values(Q, gw_custom, title=f\"{name} - Valores Q\")\n",
    "\n",
    "    # Q-values detalhados\n",
    "    visualize_q_table_detailed(Q, gw_custom, title=f\"{name} - Q-Values Detalhados\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f13901c-a592-445a-a67b-6c585579b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CODIGO AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96897c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CODIGO AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f5975e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEU CODIGO AQUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce2e10",
   "metadata": {},
   "source": [
    "# Q.5 ITEM B. VALOR 2.5 PONTOS\n",
    "\n",
    "### RESPONDA √Ä SEGUINTE QUEST√ÉO\n",
    "\n",
    "### Os algoritmos TD s√£o implementados com diferente varia√ß√µes no c√°lculo ds Q Values, essas varia√ß√µes resultam num comportamento esperado mais convervador para o algoritmo SARSA, um comportamento mais agressivo ou aproveitador para o Q-Learning e um comportamento ponderado para o Expected SARSA.\n",
    "\n",
    "### Usando as f√≥rmulas do ValoR Estado A√ß√£o de cada algoritmo explique o que causa esse comportamento, mostre se os resultados obtidos no experimento anterior evidencia ou n√£o esses comportamentos.\n",
    "\n",
    "[VERIFIQUE AS F√ìRMULAS DE ATUAIZA√á√ÉO DE CADA ALGORITMO NESTE LINK](https://github.com/DeepFluxion/IBMEC_Aprendizado_Reforco/blob/main/GridWorld_Project/Resumo_Teorico_TD_MC.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f70d7",
   "metadata": {},
   "source": [
    "# Q.6 ITEM A VALOR 0.5 PONTOS\n",
    "\n",
    "### Elabore uma an√°lise comparativa do comportamento do algoritmo SARSA para diferentes valores de Œ± (alpha) (0.01, 0.1 e 0.5)\n",
    "\n",
    "Use o c√≥digo abaixo\n",
    "```python\n",
    "# Testar diferentes valores de alpha\n",
    "alphas = [0.01,  \n",
    "          0.1,  \n",
    "          0.5]\n",
    "results_alpha = {}\n",
    "\n",
    "print(\"AN√ÅLISE DE SENSIBILIDADE - PAR√ÇMETRO ALPHA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\n‚Üí Treinando com Œ± = {alpha}...\")\n",
    "    Q, rewards = sarsa(\n",
    "        gw_custom,\n",
    "        n_episodes=5000,\n",
    "        alpha=alpha,\n",
    "        gamma=0.95,\n",
    "        epsilon=0.1\n",
    "    )\n",
    "\n",
    "    results_alpha[f'Œ±={alpha}'] = rewards\n",
    "\n",
    "    # Calcular valor m√©dio\n",
    "    values = []\n",
    "    for state in gw_custom.states:\n",
    "        if not gw_custom.is_terminal(state) and state not in gw_custom.walls:\n",
    "            state_idx = state[0] * gw_custom.cols + state[1]\n",
    "            values.append(np.max(Q[state_idx]))\n",
    "\n",
    "    avg_value = np.mean(values)\n",
    "    print(f\"   Valor m√©dio final: {avg_value:.4f}\")\n",
    "\n",
    "# Plotar compara√ß√£o\n",
    "plot_learning_curves(results_alpha, window=100,\n",
    "                    title=\"Sensibilidade ao Œ± (Taxa de Aprendizado)\")\n",
    "\n",
    "print(\"\\n‚úì An√°lise conclu√≠da!\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428645fe",
   "metadata": {},
   "source": [
    "# Q.6 ITEM B VALOR 1.5 PONTOS\n",
    "\n",
    "### Explique com detalhes o que √© o Œ± (alpha) nos algoritmos de Diferen√ßa Temporal, esclarecendo qual seu efeito nas atualiza√ß√£o de valor, demonstrando sua argumenta√ß√£o com os resultados obtidos no experimento do item anterior (Q.6 ITEM A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28914b6",
   "metadata": {},
   "source": [
    "## Q.7 VALOR 1.5 PONTOS\n",
    "\n",
    "### Ao analisar as pol√≠ticas resultantes dos experimentos algumas a√ß√µes podem ser inconsistentes. Avalie os resultados obtidos nas quest√µes Q.2 at√© Q.4 e verifique a√ß√µes que sugerem inconsist√™ncia e apresente aqui suas argumenta√ß√µes em caso positivo ou negativo, mostrando nos gr√°ficos obtidos.\n",
    "\n",
    "### Imagine que nestes experimentos voc√™ verificou que uma a√ß√£o n√£o √© consistente para uma politica √≥tima e precisa validar isso usando as ferramentas aprendidas, elabore um roteiro de como voc√™ faria est√° analise, n√£o precisa escrever os script apenas as ferramentas algoritmos implementados, gr√°ficos, an√°lises etc..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131651ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
